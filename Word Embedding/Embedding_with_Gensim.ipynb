{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVBz3cj0IZgf",
        "outputId": "af98b8e9-41c9-436d-9c09-501d2a5b3a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')  # Make sure to download the punkt tokenizer data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKWU-7gBTdKe",
        "outputId": "c138b2fc-a94b-4f66-a375-644dffc39b4b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sentences\n",
        "sentences = [\n",
        "    \"Word embeddings are a type of word representation that allows words to be represented as vectors in a continuous vector space.\",\n",
        "    \"They capture semantic meaning and relationships between words.\",\n",
        "    \"Gensim is a popular Python library for working with word embeddings.\"\n",
        "]"
      ],
      "metadata": {
        "id": "FAkojmBVTniO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences into words\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]"
      ],
      "metadata": {
        "id": "Cdl7bloJTqf8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "-97M7oR5TtRE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"word2vec_model\")\n",
        "\n",
        "# To load the model later\n",
        "# model = Word2Vec.load(\"word2vec_model\")"
      ],
      "metadata": {
        "id": "oPy4a1wVTvck"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the word vector for a specific word\n",
        "# Word must be placed in your sentence or it'll give you an error\n",
        "word_vector = model.wv['representation']\n",
        "print(f\"Vector for 'representation': {word_vector}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHPj-xV8T0V1",
        "outputId": "3b982543-c2ef-4e9c-f37a-10c3597e7358"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'representation': [-0.00950455  0.00956604 -0.00777388 -0.00264633 -0.00490923 -0.00496977\n",
            " -0.008028   -0.00778648 -0.00455546 -0.0012771  -0.00510556  0.00614231\n",
            " -0.00952082 -0.00530867  0.00944171  0.00699504  0.00767972  0.00423753\n",
            "  0.00050633 -0.00598501  0.006023    0.00263738  0.00770338  0.00639655\n",
            "  0.00794585  0.0086622  -0.00990034 -0.00675954  0.00133734  0.00644433\n",
            "  0.00737668  0.00551961  0.00766588 -0.00512967  0.00658705 -0.00410971\n",
            " -0.00906021  0.00914557  0.00133148 -0.00276083 -0.00247738 -0.00422327\n",
            "  0.00481476  0.00440208 -0.00265344 -0.00734516 -0.00356821 -0.00033755\n",
            "  0.00610017 -0.00283854 -0.00012232  0.00087883 -0.00709825  0.00206546\n",
            " -0.00143273  0.00280469  0.00484452 -0.00135231 -0.00278105  0.00774257\n",
            "  0.0050489   0.00671678  0.00451764  0.00867224  0.00747844 -0.00108075\n",
            "  0.00875089  0.00460509  0.00544317 -0.00138655 -0.00204108 -0.00442671\n",
            " -0.00851825  0.00303921  0.00888795  0.00892465 -0.00194259  0.00608829\n",
            "  0.00378151 -0.00429824  0.00204282 -0.00544065  0.00821191  0.00543607\n",
            "  0.00318665  0.00410449  0.0086619   0.00727653 -0.00083306 -0.00707624\n",
            "  0.00838515  0.00723677  0.00173148 -0.00134795 -0.00589374 -0.00453429\n",
            "  0.00865119 -0.00313755 -0.00634252  0.00987545]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find similar words\n",
        "# Letters must be small\n",
        "similar_words = model.wv.most_similar('python', topn=3)\n",
        "print(f\"Words similar to 'python': {similar_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8EcZCwsT18F",
        "outputId": "3954ed86-d532-4686-f84b-5fff61d7bd40"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to 'python': [('type', 0.1587686389684677), ('capture', 0.14296495914459229), ('represented', 0.1285327970981598)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all words in the vocabulary\n",
        "all_words = list(model.wv.index_to_key)\n",
        "\n",
        "for word in all_words:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvlu8sBBT381",
        "outputId": "5a6be758-e0a2-4708-cf62-593c751cf939"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All words in the vocabulary:\n",
            "word\n",
            "a\n",
            ".\n",
            "words\n",
            "embeddings\n",
            "vectors\n",
            "as\n",
            "represented\n",
            "be\n",
            "to\n",
            "allows\n",
            "continuous\n",
            "that\n",
            "representation\n",
            "of\n",
            "type\n",
            "are\n",
            "in\n",
            "with\n",
            "working\n",
            "space\n",
            "they\n",
            "capture\n",
            "semantic\n",
            "meaning\n",
            "and\n",
            "relationships\n",
            "between\n",
            "gensim\n",
            "is\n",
            "popular\n",
            "python\n",
            "library\n",
            "for\n",
            "vector\n"
          ]
        }
      ]
    }
  ]
}